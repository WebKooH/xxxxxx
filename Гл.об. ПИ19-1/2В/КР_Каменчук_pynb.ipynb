{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Вариант 2"
      ],
      "metadata": {
        "id": "wVf0LqOAVfyl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузить файлы и информацией о лицах, перевести в тензорный формат и построить модель классификации."
      ],
      "metadata": {
        "id": "EYbUYVYxVjZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "1xmGKKN6ipVo"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "images = np.load('/content/drive/MyDrive/ML/кр/olivetti_faces.npy') # при необходимости укажите свой \n",
        "target = np.load('/content/drive/MyDrive/ML/кр/olivetti_faces_target.npy') # при необходимости укажите свой "
      ],
      "metadata": {
        "id": "splc8ZWeViZl"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выведем форму произвольного изображения:"
      ],
      "metadata": {
        "id": "I0dfJ3RjVvFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images[359].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVDUdg2gV27F",
        "outputId": "827284d1-f849-4e60-ebc8-544d33c19505"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выведем произвольное изображение из датасета"
      ],
      "metadata": {
        "id": "Z53Y6hBGWNOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "im = Image.fromarray(images[359] * 256)\n",
        "new_im = im.convert('RGB')\n",
        "\n",
        "display(new_im)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "RwGVdoR4WJyF",
        "outputId": "bc220623-ebee-40c0-a988-38ed026ee429"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F346D99ACD0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X=images.reshape((images.shape[0],images.shape[1]*images.shape[2]))\n",
        "# print(\"X shape:\",X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjwvOxDYv_wI",
        "outputId": "3f05cfff-386c-4a46-ce25-207c11830f1f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (400, 4096)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset_(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    X = self.X[idx]\n",
        "    y = self.y[idx]\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "U3Up3Y2E0D9E"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "\n",
        "# data = images.reshape(images.shape[0], images.shape[1] * images.shape[2])     # 64 X 64 = 4096\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, target, test_size=.2, random_state=0)\n",
        "\n",
        "batch_size = 50\n",
        "\n",
        "train_set = Dataset_(X_train, y_train)\n",
        "test_set = Dataset_(X_test, y_test)\n",
        "\n",
        "train_set[0]\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, \n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, \n",
        "                                         batch_size=batch_size,\n",
        "                                         shuffle=False)"
      ],
      "metadata": {
        "id": "HomNDimfgvV0"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(len(np.unique(target)))\n",
        "np.unique(target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "NIo0OJBu3lbT",
        "outputId": "97d3d9ff-02d3-4710-83a7-1c57e0ac9783"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
              "       34, 35, 36, 37, 38, 39], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features, labels=next(iter(test_loader))"
      ],
      "metadata": {
        "id": "a-We9_qilUC1"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ex1 = features[0]\n",
        "ex1 = torch.unsqueeze(ex1, 0)\n",
        "print('ex1:', ex1.shape)\n",
        "\n",
        "conv1 = nn.Conv2d(1, 60, kernel_size=5)\n",
        "ex2 = F.max_pool2d(conv1(ex1), 2)\n",
        "print('ex2:', ex2.shape)\n",
        "\n",
        "conv2 = nn.Conv2d(60, 120, kernel_size=5)\n",
        "ex3 = F.max_pool2d(conv2(ex2), 2)\n",
        "print('ex4:', ex3.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02-Dm9SNk59a",
        "outputId": "61c1c021-fbb8-4351-bd4b-d6dfc4110459"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ex1: torch.Size([1, 64, 64])\n",
            "ex2: torch.Size([60, 30, 30])\n",
            "ex4: torch.Size([120, 13, 13])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 30, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(30, 64, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(64*13*13, 60)\n",
        "        self.fc2 = nn.Linear(60, 50)\n",
        "        self.fc3 = nn.Linear(50, 40)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, 64*13*13) \n",
        "        x = F.tanh(self.fc1(x)) \n",
        "        x = F.tanh(self.fc2(x)) \n",
        "        x = self.fc3(x) \n",
        "        return x\n",
        "  "
      ],
      "metadata": {
        "id": "c_pDtlEDgs2J"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epoch = 20 + 1\n",
        "lr=0.05\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = Net()\n",
        "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
        "losses_list = []\n",
        "log_interval = 1\n",
        "\n",
        "for epoch in range(n_epoch): \n",
        "    running_loss = 0\n",
        "    for images, target in train_loader:\n",
        "        images = torch.unsqueeze(images, 1)\n",
        "        # images = images.view(images.shape[0], -1)\n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(images)\n",
        "        loss = criterion(output, target.to(torch.long))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    losses = running_loss/len(train_loader)\n",
        "    if epoch % log_interval == 0:\n",
        "      print(\"Epoch: {}/{} |\".format(epoch, n_epoch),\n",
        "            \"Training loss: {:.3f}..\".format(losses))\n",
        "    losses_list.append(losses)\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsrLUOaWgs8_",
        "outputId": "dbfdd94e-a475-43ea-e40b-1cb5106fbe19"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0/21 | Training loss: 4.409..\n",
            "Epoch: 1/21 | Training loss: 4.462..\n",
            "Epoch: 2/21 | Training loss: 4.338..\n",
            "Epoch: 3/21 | Training loss: 4.224..\n",
            "Epoch: 4/21 | Training loss: 4.113..\n",
            "Epoch: 5/21 | Training loss: 4.043..\n",
            "Epoch: 6/21 | Training loss: 4.092..\n",
            "Epoch: 7/21 | Training loss: 4.036..\n",
            "Epoch: 8/21 | Training loss: 4.012..\n",
            "Epoch: 9/21 | Training loss: 4.027..\n",
            "Epoch: 10/21 | Training loss: 4.062..\n",
            "Epoch: 11/21 | Training loss: 4.108..\n",
            "Epoch: 12/21 | Training loss: 4.108..\n",
            "Epoch: 13/21 | Training loss: 4.156..\n",
            "Epoch: 14/21 | Training loss: 4.122..\n",
            "Epoch: 15/21 | Training loss: 4.104..\n",
            "Epoch: 16/21 | Training loss: 4.078..\n",
            "Epoch: 17/21 | Training loss: 4.037..\n",
            "Epoch: 18/21 | Training loss: 4.051..\n",
            "Epoch: 19/21 | Training loss: 4.025..\n",
            "Epoch: 20/21 | Training loss: 3.994..\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval() # equivalent with self.train(False) \n",
        "test_loss = 0\n",
        "correct = 0\n",
        "true_list = []\n",
        "pred_list = []\n",
        "result_ = {}\n",
        "result_v = {}\n",
        "with torch.no_grad():\n",
        "    for images, target in train_loader:\n",
        "        images = torch.unsqueeze(images, 1)\n",
        "        output = model(images)\n",
        "        test_loss += criterion(output, target.to(torch.long))\n",
        "        _, pred = torch.max(output, 1)\n",
        "        # pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-p \n",
        "        correct = pred.eq(target.view_as(pred))        \n",
        "        for i in range(20):\n",
        "            target_i = target[i].item()\n",
        "            try:\n",
        "              result_v[target_i] += 1\n",
        "            except:\n",
        "              result_v[target_i] = 1\n",
        "            try:\n",
        "              result_[target_i] += 1\n",
        "            except:\n",
        "              result_[target_i] = int(correct[i].item())\n",
        "        # correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        true_list += target.numpy().tolist()\n",
        "        pred_list += np.squeeze(pred.numpy()).tolist()\n",
        "\n",
        "test_loss /= len(test_loader.dataset)\n",
        "\n",
        "print(f'Avg. loss: {test_loss:.4f}')\n",
        "for i in range(40):\n",
        "    print(f'n{i} => {result_[i]/result_v[i]:.2f}({result_[i]}/{result_v[i]})')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQ3DBSdI8qzV",
        "outputId": "82f51aa5-4771-4e10-fe94-da09d454068f"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avg. loss: 0.3332\n",
            "n0 => 0.67(2/3)\n",
            "n1 => 0.67(2/3)\n",
            "n2 => 0.75(3/4)\n",
            "n3 => 0.75(3/4)\n",
            "n4 => 0.75(3/4)\n",
            "n5 => 0.50(1/2)\n",
            "n6 => 0.50(1/2)\n",
            "n7 => 0.80(4/5)\n",
            "n8 => 0.00(0/1)\n",
            "n9 => 0.80(4/5)\n",
            "n10 => 0.67(2/3)\n",
            "n11 => 0.75(3/4)\n",
            "n12 => 0.67(2/3)\n",
            "n13 => 0.67(2/3)\n",
            "n14 => 0.67(2/3)\n",
            "n15 => 0.67(2/3)\n",
            "n16 => 0.80(4/5)\n",
            "n17 => 0.50(1/2)\n",
            "n18 => 0.00(0/1)\n",
            "n19 => 0.75(3/4)\n",
            "n20 => 0.80(4/5)\n",
            "n21 => 0.67(2/3)\n",
            "n22 => 0.83(5/6)\n",
            "n23 => 0.86(6/7)\n",
            "n24 => 0.67(2/3)\n",
            "n25 => 0.88(7/8)\n",
            "n26 => 0.75(3/4)\n",
            "n27 => 0.80(4/5)\n",
            "n28 => 0.75(3/4)\n",
            "n29 => 0.75(3/4)\n",
            "n30 => 0.00(0/1)\n",
            "n31 => 0.50(1/2)\n",
            "n32 => 0.50(1/2)\n",
            "n33 => 1.00(3/3)\n",
            "n34 => 0.00(0/1)\n",
            "n35 => 0.75(3/4)\n",
            "n36 => 0.67(2/3)\n",
            "n37 => 0.67(2/3)\n",
            "n38 => 0.75(3/4)\n",
            "n39 => 0.75(3/4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Отчетность"
      ],
      "metadata": {
        "id": "8pk7rFZ4XikY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В первую очередь в работе должна быть продемонстрирована ваша архитектура и процесс обучения (с кратким обоснованием выбора гиперпараметров).\n",
        "\n",
        "\n",
        "Далее:"
      ],
      "metadata": {
        "id": "6vwP3-cMYuBL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(В конце вашего ноутбука укажите следующие данные)\n",
        "\n",
        "По задачам классификации:\n",
        "\n",
        "1.  Вывести метрики классификации на тестовом множестве: accuracy, precision, recall и f1-score(для бинарной) и метрик качества для каждого класса, в случае использования датасета с лицами.\n",
        "2.  Обосновать выбранное соотношение train/test на основе построения кривых обучения (или понятного вывода результатов эксперимента) \n",
        "\n"
      ],
      "metadata": {
        "id": "iEYMCaizXk5w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "По задаче регрессии:\n",
        "\n",
        "\n",
        "\n",
        "1.   Вывести коэффициент детерминации и средний квадрат ошибки\n",
        "2.   Продемнострировать, что выбрано оптимальное соотношение train/test, путем перебора всех содержательных вариантов.\n",
        "\n"
      ],
      "metadata": {
        "id": "jb45JczkYadi"
      }
    }
  ]
}